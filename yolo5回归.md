#预测目标框回归原理

当我们初次看到“预测目标框回归”这个字眼的时候，往往是懵逼的，其实它也没有那么玄乎，这就是一个把网络的预测信息转换为实际目标框信息的操作。那么问题来了，为什么需要一个转换操作呢？

假如让网络直接去预测目标框的位置坐标和宽高，坐标与宽高的取值范围都太广泛了，这无疑增大了网络的训练时间和学习难度，导致网络的不稳定，严重情况下甚至使网络在错误的学习方向上渐行渐远。

为解决该问题，yolov5网络在预测信息中加入了目标框的先验信息。通俗理解，就是在网络训练之前，人为地先告诉网络目标框的信息范围，比如框中心坐标的取值范围、宽高的取值范围。然后网络在这个取值范围的基础上再去学习，以获得更精确的框信息。这样一来相当于对网络的学习方向作了限制，因此很大程度增加了网络的稳定性以及收敛速度。如下图所示：
![1](回归1.png)

具体做法：

框的中心坐标

我们在前文已经讲过，yolov5网络把640*640的图像划分成N*N（通常为80*80，或40*40，或20*20）的网格区域。网络的输出端则输出所有网格的预测信息，每个网格的预测信息包括目标的分类概率、置信度，以及目标框的x中心坐标、y中心坐标、长、宽（xpred、ypred、wpred、hpred）。对于每个网格，它预测目标框的位置就在该网格附近，因此x中心坐标、y中心坐标的大概范围是可以确定的，利用此特性可以对该网格预测的x中心坐标、y中心坐标作取值范围限制，如下式：

![1](回归2.png)


上式中，xgrid和ygrid为该网格的网格坐标（0≤xgrid<N，0≤ygrid<N），xgrid和ygrid是确定的已知信息，也即先验信息。xpred和ypred为该网格对应目标框的中心坐标预测值（0<xpred<1，0<ypred<1）。xc和yc为目标框的回归中心坐标值，也即经过转换之后的目标框中心坐标，根据上式得到xc和yc的取值范围如下，相对网格坐标偏移-0.5~1.5，这符合目标框位置在该网格附近的事实。

![1](回归3.png)

![1](回归4.png)

#框的宽、高

预测目标框的宽、高也加入了先验信息：

![1](回归5.png)


上式中，wpred和hpred为网络输出的目标框宽、高预测值（0<wpred<1，0<hpred<1），wanchor和hanchor为该目标框宽、高的先验信息，也即事先告诉网络该目标框宽、高的取值范围：

![1](回归6.png)

那么wanchor和hanchor又是怎么事先得到的呢？这就需要对训练集包含的所有目标框的宽、高做统计分析了——统计训练集中所有目标框的宽、高，并从中提取出几个主要的宽、高组合，也即最具有代表性的宽、高组合，这几个宽高组合对应的几个方框，就是我们所说的anchor框。yolov5网络使用kmeans算法将训练集所包含所有目标框的宽、高进行聚类，得到9个最具有代表性的宽、高组合，也即9个anchor框，然后根据宽、高的大小把这9个anchor分成3组：

宽、高最小的3个anchor框分配给80*80网格的每一个格子

宽、高居中的3个anchor框分配给40*40网格的每一个格子

宽、高最大的3个anchor框分配给20*20网格的每一个格子

这与前文我们说的每一层网格输出信息就对应了起来，以下3*80*80、3*40*40、3*20*20中的数字3也即对应上方的3个anchor框：

80*80网格输出3*80*80个小尺寸检测目标的信息

40*40网格输出3*40*40个中尺寸检测目标的信息

20*20网格输出3*20*20个大尺寸检测目标的信息